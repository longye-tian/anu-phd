\section{Model}

\begin{frame}{Components}
    \begin{itemize}
        \item Finite state space:  $\mathbf{X}$
        \item State process:  $X_t\in \mathbf{X}$
        \item Finite action space:  $\mathbf{A}$ 
        \item  Action process:  $A_t\in \mathbf{A}$
        \item Discount factor:  $\beta\in(0,1)$
        \item Nonempty feasible state-action correspondence: $\Gamma: \mathbf{X}\to \mathbf{A}$
        \item Feasible state-action pair: $G:=\{(x,a)\in \mathbf{X}\times\mathbf{A}: a\in\Gamma(x)\}$
    \end{itemize}
\end{frame}

\begin{frame}{Components}
    \begin{itemize}
        \item Stochastic kernel: $P:G\times X\to [0,1]$
        \item Set of feasible policies 
        $$
        \Sigma:=\{\sigma\in \mathbf{A}^{\mathbf{X}}: \sigma(x) \in \Gamma(x)\text{ for all $x\in \mathbf{X}$}\}
        $$
        \item Markov operator: 
        $$
        P_\sigma (x,x') = P(x,\sigma(x),x')
        $$
        \item Reward function: $r:G\to \mathbb{R}$ and $r_\sigma(x,a) = r(x,\sigma(x))$
        \item Lifetime value of $\sigma$ with initial value $X_0=x$
        $$
        v_\sigma (x) := \mathbb{E}\sum_{t\ge 0} \beta^t r(X_t,\sigma(X_t))
        $$
        where $(X_t)_{t\ge 0}$ is the \textbf{Markov Chain} generated by $P_\sigma$ with initial condition $X_0=x$. Pointwise, we have
        $$
        v_\sigma  = \sum_{t\ge 0} (\beta P_\sigma)^tr_\sigma  = (I-\beta P_\sigma)^{-1}r_\sigma
        $$
    \end{itemize}
\end{frame}